В ходе выполнения домашнего задания №1 закреплены на практике темы лекций, относящихся к линейной регрессии, на примере 
предсказания цен автомобилей индийского авторынка.

Для выполнения поставленных задач проделаны следующие шаги и получены описанные ниже результаты.

*** Исследование данных. 
1) Проведено базовое исследование данных при помощи jupyter notebook, а также дашбордов, построенных с использованием 
   библиотеки ydata-profilling. 
2) Выявлены и удалены полные дубликаты в данных. Также обнаружены объекты с одинаковым признаковым описанием.
3) Обнаружены пропуски в числовых атрибутах, которые впоследствии будут заполнены медианным значением.
4) Определены объектные столбцы, данные в которых требуют дополнительной обработки для извлечения из них одного или 
   более числовых признаков, например milage, engine, max_power и torque. 
5) Обнаружена заметная разница медианных значений пробега и цены продажи, из чего можно сделать вывод о наличии выбросов.
6) Построены графики попарных зависимостей признаков, на основании которых сделан вывод о наличии линейной связи цены
   продажи авто от характеристик двигателя, таких как мощность, объем, крутящий момент и расход топлива.
7) Подтверждены предположения о наличии квадратичной зависимости цены продажи от года выпуска, а также обратной 
   зависимости от пробега.
8) Выводы из графиков подтверждены анализом матрицы корреляций. Реализован собственный алгоритм расчета коэффициентов
   корреляции Спирмена и phik с результатами, близкими к библиотечной реализации этих функций.

*** Построение модели на числовых признаках.   
1) Построена базовая модель линейной регрессии на вещественных признаках с параметрами по умолчанию. Предсказательная
   способность такой модели оказалась удовлетворительной, открывая возможности для дальнейшего улучшения.
2) В качестве упражнения реализованы метрики R^2 и adjusted R^2 и проанализированы области их применения.
3) Проведено масштабирование признаков при помощи StandardScaler, на основании которого подтверждено предположение о 
   наибольшей значимости признака max_power для предсказания целевой переменной.
4) В ходе исследования проведена L1 регуляризация признаков при помощи Lasso, которая не привела к занулению ни одного 
   из весов, а также улучшению качества прогноза.
5) Использована кросс-валидация с 10-ю фолдами для поиска оптимального значения параметров Lasso регрессии. Подобрано
   лучшее значение коэф-та регуляризации alpha, при этом модель занулила два из 8 весов. Значение метрики R^2 у 
   полученной модели оказалось ниже, чем у базовой. Возможно, где-то была допущена ошибка при работе с признаками, хотя 
   выявить возможную ошибку не получилось.
6) Также построена модель ElasticNet, комбинирующая алгоритмы L1 и L2 регуляризации и получено оптимальное значение 
   гиперпараметров alpha и l1_ratio. Существенного улучшения качества модели при этом не выявлено.
7) В качестве теста реализован алгоритм L0 регуляризации с отбором признаков на основании порога весов. По метрике R^2
   наилучшей оказалась модель с 8 признаками (т.е. без удаления).

*** Добавление категориальных признаков в модель
1) Столбец Name преобразован таким образом, чтобы оставить только название марки авто. Стобец seats преобразован в 
   категориальный признак.
2) Категориальные признаки закодированы при помощи OneHotEncoding(OHE). Определена область применимости OHE, к 
   которой относят признаки с невысокой кардинальностью. Акцентировано внимание на необходимости удаления первого
   столбца во избежание мультиколинеарности. Проанализирована корректность удаления OHE признаков, оцененных в 
   дальнейшем как неважные.
3) Построена модель на комбинированных признаках с использованием Ridge регрессии и кросвалидации на 10 фолдах с 
   подбором наилучшего значения гиперпараметра alpha. При этом качество прогноза значительно улучшилось по сравнению с 
   baseline моделью. Однако рассчитанный по кросс-валидации гиперпараметр alpha оказался очень маленьким и причина 
   такого результата не совсем ясна.  

*** Feature Engineering и бизнес-метрики
В качестве бонусной части Feature Engineering выполнены следующие шаги по улучшению модели.
1) Добавлен атрибут year^2, т.к. зависимость цены продажи от года на графиках выглядит как квадратичная.
2) Добавлен признак 1/km_driven, т.к. цена автомобиля убывает с увеличением пробега, но не линейно.
3) Проделаны эксперименты с атрибутом Name. Лучший результат показала модель, использующая Name без предобработки.
4) StandardScaler изменен на MinMaxScaler, как более подходящий к использованию совместно с OHE.
5) Операции по работе с моделью помещены в Pipeline. Хотя это не имеет отношения к FeatureEngineering, 
   но существенно упрощает написание сервиса, требуемого в дальнейшем задании.
6) Сделан вывод о существенном улучшении качества модели в результате описанных выше действия. 
7) Дополнительно реализованы две бизнес-метрики и обучена модель для их оптимизации (максимизации). Алгоритм реализации 
   метрик выглядит правильным, но результат вычисления R^2 и MSE оказался очень близок к значению предыдущей модели, где 
   минимизировалась стандатртная квадратичная фунцией потерь (MSE). Здесь необходимо более детальное исследование.

*** Сервис на fastapi
1) Создан сервис на fastapi с реализацией rest api использованием типизации pydentic.
2) Реализована функция предсказания цены одного объекта с передачей атрибутов в виде json.
3) Реализована функция предсказания цены для списка объектов, переданных в виде csv файла.

*** Оформление
Ход и результаты работы подробно описаны в данном документе. Исходный код сервиса и ноутбук снабжены подробными 
комментариями.

Прилагаемые артефакты:
1. ML_Homework1.ipnb - ноутбук с выполненными заданиями.
2. ridge_model.pickle - файл модели, использованной сервисом.
2. car_price_service.py - код реализации сервиса на fastapi.
3. dashboard_train.html, dashboard_test.html - результаты генерации дашбордов с использованием ydata-profilling.
4. Homework_1_screencast.mp4 - скринкаст с демонстрацией работы сервиса.
5. readme.md - файл с описанием проделанной работы.


*** Чей кот
Не знаю, но порода достаточно редкая - Девон-рекс или Корниш-рекс - и требует повышенного внимания и ухода. Вероятно, 
автор - девушка, и в марте 2020 она использовала неплохой Iphone XR за $600.